{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Step : 0, training accuracy : 0.04\n",
      "Step : 100, training accuracy : 0.78\n",
      "Step : 200, training accuracy : 0.92\n",
      "Step : 300, training accuracy : 0.92\n",
      "Step : 400, training accuracy : 0.98\n",
      "Step : 500, training accuracy : 0.92\n",
      "Step : 600, training accuracy : 0.98\n",
      "Step : 700, training accuracy : 0.98\n",
      "Step : 800, training accuracy : 0.88\n",
      "Step : 900, training accuracy : 1\n",
      "Step : 1000, training accuracy : 0.96\n",
      "Step : 1100, training accuracy : 0.94\n",
      "Step : 1200, training accuracy : 0.94\n",
      "Step : 1300, training accuracy : 0.98\n",
      "Step : 1400, training accuracy : 0.98\n",
      "Step : 1500, training accuracy : 0.94\n",
      "Step : 1600, training accuracy : 0.98\n",
      "Step : 1700, training accuracy : 1\n",
      "Step : 1800, training accuracy : 1\n",
      "Step : 1900, training accuracy : 1\n",
      "Step : 2000, training accuracy : 0.98\n",
      "Step : 2100, training accuracy : 1\n",
      "Step : 2200, training accuracy : 0.96\n",
      "Step : 2300, training accuracy : 0.98\n",
      "Step : 2400, training accuracy : 1\n",
      "Step : 2500, training accuracy : 1\n",
      "Step : 2600, training accuracy : 0.96\n",
      "Step : 2700, training accuracy : 0.98\n",
      "Step : 2800, training accuracy : 0.96\n",
      "Step : 2900, training accuracy : 1\n",
      "Step : 3000, training accuracy : 1\n",
      "Step : 3100, training accuracy : 0.98\n",
      "Step : 3200, training accuracy : 1\n",
      "Step : 3300, training accuracy : 1\n",
      "Step : 3400, training accuracy : 1\n",
      "Step : 3500, training accuracy : 1\n",
      "Step : 3600, training accuracy : 0.98\n",
      "Step : 3700, training accuracy : 1\n",
      "Step : 3800, training accuracy : 1\n",
      "Step : 3900, training accuracy : 0.98\n",
      "Step : 4000, training accuracy : 0.98\n",
      "Step : 4100, training accuracy : 0.98\n",
      "Step : 4200, training accuracy : 1\n",
      "Step : 4300, training accuracy : 0.98\n",
      "Step : 4400, training accuracy : 0.98\n",
      "Step : 4500, training accuracy : 1\n",
      "Step : 4600, training accuracy : 1\n",
      "Step : 4700, training accuracy : 1\n",
      "Step : 4800, training accuracy : 1\n",
      "Step : 4900, training accuracy : 1\n",
      "Step : 5000, training accuracy : 1\n",
      "Step : 5100, training accuracy : 0.98\n",
      "Step : 5200, training accuracy : 1\n",
      "Step : 5300, training accuracy : 1\n",
      "Step : 5400, training accuracy : 1\n",
      "Step : 5500, training accuracy : 0.98\n",
      "Step : 5600, training accuracy : 1\n",
      "Step : 5700, training accuracy : 1\n",
      "Step : 5800, training accuracy : 0.98\n",
      "Step : 5900, training accuracy : 1\n",
      "Step : 6000, training accuracy : 1\n",
      "Step : 6100, training accuracy : 1\n",
      "Step : 6200, training accuracy : 0.98\n",
      "Step : 6300, training accuracy : 1\n",
      "Step : 6400, training accuracy : 1\n",
      "Step : 6500, training accuracy : 0.96\n",
      "Step : 6600, training accuracy : 1\n",
      "Step : 6700, training accuracy : 1\n",
      "Step : 6800, training accuracy : 0.96\n",
      "Step : 6900, training accuracy : 1\n",
      "Step : 7000, training accuracy : 0.98\n",
      "Step : 7100, training accuracy : 1\n",
      "Step : 7200, training accuracy : 1\n",
      "Step : 7300, training accuracy : 1\n",
      "Step : 7400, training accuracy : 1\n",
      "Step : 7500, training accuracy : 1\n",
      "Step : 7600, training accuracy : 1\n",
      "Step : 7700, training accuracy : 1\n",
      "Step : 7800, training accuracy : 0.98\n",
      "Step : 7900, training accuracy : 1\n",
      "Step : 8000, training accuracy : 0.98\n",
      "Step : 8100, training accuracy : 1\n",
      "Step : 8200, training accuracy : 1\n",
      "Step : 8300, training accuracy : 1\n",
      "Step : 8400, training accuracy : 1\n",
      "Step : 8500, training accuracy : 1\n",
      "Step : 8600, training accuracy : 0.98\n",
      "Step : 8700, training accuracy : 1\n",
      "Step : 8800, training accuracy : 1\n",
      "Step : 8900, training accuracy : 0.98\n",
      "Step : 9000, training accuracy : 1\n",
      "Step : 9100, training accuracy : 1\n",
      "Step : 9200, training accuracy : 0.98\n",
      "Step : 9300, training accuracy : 0.98\n",
      "Step : 9400, training accuracy : 1\n",
      "Step : 9500, training accuracy : 0.98\n",
      "Step : 9600, training accuracy : 0.96\n",
      "Step : 9700, training accuracy : 1\n",
      "Step : 9800, training accuracy : 0.96\n",
      "Step : 9900, training accuracy : 1\n",
      "Step : 10000, training accuracy : 1\n",
      "Step : 10100, training accuracy : 0.98\n",
      "Step : 10200, training accuracy : 1\n",
      "Step : 10300, training accuracy : 1\n",
      "Step : 10400, training accuracy : 1\n",
      "Step : 10500, training accuracy : 1\n",
      "Step : 10600, training accuracy : 1\n",
      "Step : 10700, training accuracy : 1\n",
      "Step : 10800, training accuracy : 1\n",
      "Step : 10900, training accuracy : 1\n",
      "Step : 11000, training accuracy : 1\n",
      "Step : 11100, training accuracy : 1\n",
      "Step : 11200, training accuracy : 1\n",
      "Step : 11300, training accuracy : 1\n",
      "Step : 11400, training accuracy : 0.98\n",
      "Step : 11500, training accuracy : 1\n",
      "Step : 11600, training accuracy : 1\n",
      "Step : 11700, training accuracy : 1\n",
      "Step : 11800, training accuracy : 1\n",
      "Step : 11900, training accuracy : 0.98\n",
      "Step : 12000, training accuracy : 1\n",
      "Step : 12100, training accuracy : 1\n",
      "Step : 12200, training accuracy : 1\n",
      "Step : 12300, training accuracy : 1\n",
      "Step : 12400, training accuracy : 1\n",
      "Step : 12500, training accuracy : 0.98\n",
      "Step : 12600, training accuracy : 1\n",
      "Step : 12700, training accuracy : 1\n",
      "Step : 12800, training accuracy : 1\n",
      "Step : 12900, training accuracy : 1\n",
      "Step : 13000, training accuracy : 1\n",
      "Step : 13100, training accuracy : 1\n",
      "Step : 13200, training accuracy : 1\n",
      "Step : 13300, training accuracy : 1\n",
      "Step : 13400, training accuracy : 1\n",
      "Step : 13500, training accuracy : 1\n",
      "Step : 13600, training accuracy : 1\n",
      "Step : 13700, training accuracy : 1\n",
      "Step : 13800, training accuracy : 0.98\n",
      "Step : 13900, training accuracy : 1\n",
      "Step : 14000, training accuracy : 1\n",
      "Step : 14100, training accuracy : 0.98\n",
      "Step : 14200, training accuracy : 1\n",
      "Step : 14300, training accuracy : 1\n",
      "Step : 14400, training accuracy : 0.98\n",
      "Step : 14500, training accuracy : 1\n",
      "Step : 14600, training accuracy : 1\n",
      "Step : 14700, training accuracy : 1\n",
      "Step : 14800, training accuracy : 1\n",
      "Step : 14900, training accuracy : 1\n",
      "Step : 15000, training accuracy : 1\n",
      "Step : 15100, training accuracy : 1\n",
      "Step : 15200, training accuracy : 1\n",
      "Step : 15300, training accuracy : 0.98\n",
      "Step : 15400, training accuracy : 0.98\n",
      "Step : 15500, training accuracy : 1\n",
      "Step : 15600, training accuracy : 1\n",
      "Step : 15700, training accuracy : 1\n",
      "Step : 15800, training accuracy : 0.98\n",
      "Step : 15900, training accuracy : 1\n",
      "Step : 16000, training accuracy : 1\n",
      "Step : 16100, training accuracy : 1\n",
      "Step : 16200, training accuracy : 1\n",
      "Step : 16300, training accuracy : 1\n",
      "Step : 16400, training accuracy : 1\n",
      "Step : 16500, training accuracy : 1\n",
      "Step : 16600, training accuracy : 1\n",
      "Step : 16700, training accuracy : 1\n",
      "Step : 16800, training accuracy : 1\n",
      "Step : 16900, training accuracy : 1\n",
      "Step : 17000, training accuracy : 1\n",
      "Step : 17100, training accuracy : 1\n",
      "Step : 17200, training accuracy : 1\n",
      "Step : 17300, training accuracy : 1\n",
      "Step : 17400, training accuracy : 1\n",
      "Step : 17500, training accuracy : 1\n",
      "Step : 17600, training accuracy : 0.98\n",
      "Step : 17700, training accuracy : 1\n",
      "Step : 17800, training accuracy : 1\n",
      "Step : 17900, training accuracy : 1\n",
      "Step : 18000, training accuracy : 1\n",
      "Step : 18100, training accuracy : 0.98\n",
      "Step : 18200, training accuracy : 1\n",
      "Step : 18300, training accuracy : 1\n",
      "Step : 18400, training accuracy : 1\n",
      "Step : 18500, training accuracy : 1\n",
      "Step : 18600, training accuracy : 1\n",
      "Step : 18700, training accuracy : 1\n",
      "Step : 18800, training accuracy : 1\n",
      "Step : 18900, training accuracy : 1\n",
      "Step : 19000, training accuracy : 1\n",
      "Step : 19100, training accuracy : 1\n",
      "Step : 19200, training accuracy : 1\n",
      "Step : 19300, training accuracy : 1\n",
      "Step : 19400, training accuracy : 1\n",
      "Step : 19500, training accuracy : 1\n",
      "Step : 19600, training accuracy : 0.98\n",
      "Step : 19700, training accuracy : 1\n",
      "Step : 19800, training accuracy : 1\n",
      "Step : 19900, training accuracy : 1\n",
      "Test Accuracy : 0.9923\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "def weightVariables(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def biasVariable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def maxPool2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def main():\n",
    "    '''PlaceHolders'''\n",
    "    # Input\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    # Target\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "    \n",
    "    #  First Convolutional Layer\n",
    "    wConv1 = weightVariables([5, 5, 1, 32])\n",
    "    bConv1 = biasVariable([32])\n",
    "    xImage = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    hConv1 = tf.nn.relu(conv2d(xImage, wConv1) + bConv1)\n",
    "    hPool1 = maxPool2x2(hConv1)\n",
    "    # Ouput : 14 * 14\n",
    "    \n",
    "    #  Second Convolutional Layer\n",
    "    wConv2 = weightVariables([5, 5, 32, 64])\n",
    "    bConv2 = biasVariable([64])\n",
    "    hConv2 = tf.nn.relu(conv2d(hPool1, wConv2) + bConv2)\n",
    "    hPool2 = maxPool2x2(hConv2)\n",
    "    # Output : 7 * 7\n",
    "    \n",
    "    # Densely Connected Layer\n",
    "    wFC1 = weightVariables([7 * 7 * 64, 1024])\n",
    "    bFC1 = biasVariable([1024])\n",
    "    hPool2Flat = tf.reshape(hPool2, [-1, 7*7*64])\n",
    "    hFC1 = tf.nn.relu(tf.matmul(hPool2Flat, wFC1) + bFC1)\n",
    "    \n",
    "    # Dropout\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    hFC1Drop = tf.nn.dropout(hFC1, keep_prob)\n",
    "    \n",
    "    wFC2 = weightVariables([1024, 10])\n",
    "    bFC2 = biasVariable([10])\n",
    "    \n",
    "    yConv = tf.matmul(hFC1Drop, wFC2) + bFC2\n",
    "    \n",
    "    \n",
    "    #  Train ans evaluate the model:\n",
    "    crossEntropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=yConv))\n",
    "    trainStep = tf.train.AdamOptimizer(1e-4).minimize(crossEntropy)\n",
    "    \n",
    "    correctPrediction = tf.equal(tf.argmax(yConv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctPrediction, tf.float32))\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(20000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i%100 == 0:\n",
    "            trainAccuracy = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0 \n",
    "            })\n",
    "            print(\"Step : %d, training accuracy : %g\"%(i, trainAccuracy))\n",
    "            \n",
    "        trainStep.run(feed_dict={\n",
    "            x: batch[0], y_: batch[1], keep_prob: 0.5\n",
    "        })\n",
    "        \n",
    "    print(\"Test Accuracy : %g\"%accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0\n",
    "    }))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
